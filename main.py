import base64
import cv2
import gradio as gr
import librosa
import matplotlib.pyplot as plt
import numpy as np
import os
import requests
import soundfile as sf
import tempfile
import torch
import whisper
import easyocr

from PIL import Image, ImageDraw, ImageFont
from io import BytesIO
from skimage import io

from transformers import (
    AutoModelForCausalLM,
    AutoModelForImageSegmentation,
    AutoModelForZeroShotObjectDetection,
    AutoTokenizer,
    AutoProcessor,
    CLIPModel,
    CLIPProcessor,
    CLIPSegProcessor, 
    CLIPSegForImageSegmentation,
    pipeline,
)

from segment_anything import sam_model_registry, SamPredictor

from diffusers import DiffusionPipeline
from dotenv import load_dotenv

import tensorflow as tf
import tensorflow_hub as hub
from torchvision import transforms
from torchvision.transforms.functional import normalize

from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
################################################
from object_utils import detect_and_segment_object, sam_integration_method, place_object_optimally
from video_utils import extract_frames, clip_similarity
################################################

import warnings
warnings.filterwarnings("ignore")

load_dotenv()
################################################ 1.TAB ################################################

def all_function(input_img, query_text, background_img):
    img, x0, y0, x1, y1 = detect_and_segment_object(input_img, query_text)
    cropped_img = sam_integration_method(img, x0, y0, x1, y1)
    final_img = place_object_optimally(object_image=cropped_img, background_image= background_img, query_text= query_text)
    return final_img

################################################ 2.TAB ################################################
def clip_similarity_1(image, texts):
    """CLIP ile gÃ¶rÃ¼ntÃ¼-metin benzerlik analizi"""
    clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
    clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
    texts = [t.strip() for t in texts.split(",")]
    inputs = clip_processor(text=texts, images=image, return_tensors="pt", padding=True)
    with torch.no_grad():
        outputs = clip_model(**inputs)  
    probs = outputs.logits_per_image.softmax(dim=1).squeeze().tolist()
    return dict(sorted(zip(texts, probs), key=lambda x: x[1], reverse=True))

################################################ 3.TAB ################################################
def image_to_base64(image_path): 
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")

# GÃ¶rsel Soru-Cevap fonksiyonu
def visual_question_answering_chatbot(history, image, question):
    # GeÃ§ici olarak resmi kaydet (base64 dÃ¶nÃ¼ÅŸÃ¼m iÃ§in)
    with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp_file:
        image.save(tmp_file.name)
        image_path = tmp_file.name

    # LLM Ã§aÄŸrÄ±sÄ±
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.3)

    # Sistem mesajÄ±
    system_message = SystemMessage(content="""
    Sen bir gÃ¶rsel soru-cevap uzmanÄ±sÄ±n. Resmi analiz edip kullanÄ±cÄ±nÄ±n sorusunu yanÄ±tlamalÄ±sÄ±n.
    """)

    # GÃ¶rseli base64'e Ã§evir ve Gemini'ye uygun ÅŸekilde hazÄ±rla
    image_base64 = image_to_base64(image_path)
    user_message = HumanMessage(content=[
        {"type": "text", "text": question},
        {"type": "image_url", "image_url": f"data:image/jpeg;base64,{image_base64}"}
    ])

    # Sohbet geÃ§miÅŸine sistem mesajÄ±nÄ± ve kullanÄ±cÄ± mesajÄ±nÄ± ekle
    response = llm.invoke([system_message, user_message])
    history.append((question, response.content))
    return history, ""

################################################ 4.TAB ################################################
def image_description(image):
    pipe = pipeline("image-to-text", model="Salesforce/blip-image-captioning-base")
    result = pipe(image)
    return result[0]['generated_text']

################################################ 5.TAB ################################################
def extract_text_from_image(image):
    reader = easyocr.Reader(['tr', 'en'], gpu=False)
    image_np = np.array(image)  # PIL â†’ NumPy
    results = reader.readtext(image_np)

    extracted_text = []
    for (bbox, text, prob) in results:
        extracted_text.append(f"{text} (GÃ¼ven: {prob:.2f})")
    
    return "\n".join(extracted_text) if extracted_text else "Metin bulunamadÄ±."

################################################ 6.TAB ################################################

def analyze_video(video_path):
    # 1. Frame Ã§Ä±kar
    frame_paths = extract_frames(video_path)

    # 2. CLIP ile skorlama
    scored_frames = clip_similarity(frame_paths)

    # 3. En iyi 5 frame + skorlarÄ±
    top_5 = scored_frames[:5]
    top_5_paths = [item[0] for item in top_5]
    scores_text = "\n".join([f"{os.path.basename(p)}: {s:.4f}" for p, s in top_5])

    return top_5_paths, scores_text

################################################ 7.TAB ################################################

def transcribe_audio(audio_file, language="en"):
    try:
        model = whisper.load_model("base")
        result = model.transcribe(audio_file, language=language)
        return result["text"]
    except Exception as e:
        return f"Bir hata oluÅŸtu: {e}"

################################################ 8.TAB ################################################
def classify_music_genre(input_path: str):

    if not os.path.exists(input_path):
        return "Dosya bulunamadÄ±."

    filename, ext = os.path.splitext(input_path)
    if ext.lower() not in [".mp3", ".wav"]:
        return "LÃ¼tfen .mp3 veya .wav formatÄ±nda bir dosya yÃ¼kleyin."

    wav_path = input_path

    try:
        y, sr = librosa.load(input_path, sr=16000, duration=30)
        
        wav_path = filename + "_30s.wav"
        sf.write(wav_path, y, sr)
    except Exception as e:
        return f"Ses iÅŸleme hatasÄ±: {e}"

    try:
        classifier = pipeline("audio-classification", model="dima806/music_genres_classification")
        preds = classifier(wav_path)
    except Exception as e:
        return f"Model hatasÄ±: {e}"

    if os.path.exists(wav_path) and wav_path != input_path:
        os.remove(wav_path)

    if not preds:
        return "Tahmin yapÄ±lamadÄ±."

    result = f"En olasÄ± tÃ¼r: **{preds[0]['label']}** ({preds[0]['score']:.2f})\n\n"
    result += "DiÄŸer Tahminler:\n"
    for pred in preds[1:]:
        result += f"- {pred['label']}: {pred['score']:.2f}\n"
    return result

################################################ 9.TAB ################################################

def stable_diffusion(prompt):
    pipe = DiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4")
    pipe = pipe.to("cuda" if torch.cuda.is_available() else "cpu")
    image = pipe(prompt).images[0]
    return image

################################################ 10.TAB ################################################

def load_image(image_path, image_size=(256, 256)):
    img = Image.open(image_path).convert('RGB').resize(image_size)
    img = np.array(img) / 255.0
    img = img.astype(np.float32)
    img = np.expand_dims(img, axis=0)
    return img

def apply_style_transfer(content_img_path, style_img_path, image_size=(256, 256)):
    hub_module = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')

    content_image = load_image(content_img_path, image_size)
    style_image = load_image(style_img_path, image_size)

    outputs = hub_module(tf.constant(content_image), tf.constant(style_image))
    stylized_image = outputs[0][0].numpy()  # [0] batch, sonra tensor â†’ numpy

    stylized_image = (stylized_image * 255).astype(np.uint8)
    return Image.fromarray(stylized_image)


#######################################################################################################

with gr.Blocks() as demo:
    gr.Markdown("## Multimodal AI UygulamalarÄ±")
    
    with gr.Tabs():
        with gr.TabItem("Nesne KÄ±rpma ve Ekleme"):
            gr.Markdown("**Nesne kÄ±rpma ve arkaplana ekleme**")

            with gr.Row():  # Hepsi yatayda olacak
                input_mode = gr.Radio(
                    ["Resim YÃ¼kle", "Metin Gir"],
                    label="ğŸ” GiriÅŸ Tipi SeÃ§in",
                    value="Resim YÃ¼kle"
                )

                input_img = gr.Image(
                    type="filepath",
                    label="ğŸ¯ Nesne GÃ¶rseli (YÃ¼kleyin)",
                    visible=True
                )

                input_text = gr.Textbox(
                    label="âœï¸ Resim Linki",
                    placeholder="http.example.com/image.jpg",
                    visible=False
                )

                background_img = gr.Image(
                    type="filepath",
                    label="ğŸï¸ Arka Plan GÃ¶rseli (YÃ¼kleyin)"
                )

                query_text = gr.Textbox(
                    label="ğŸ¯ KÄ±rpÄ±lacak Nesne",
                    placeholder="a dog.",
                    info="Buraya kÄ±rpÄ±lacak nesneyi yazÄ±n. Ã–rn: a cat."
                )

            output_image = gr.Image(label="ğŸ–¼ï¸ SonuÃ§ GÃ¶rseli")

            submit_button = gr.Button("ğŸš€ Uygula")

            # GiriÅŸ tÃ¼rÃ¼ne gÃ¶re gÃ¶sterim deÄŸiÅŸtirme
            def toggle_input_visibility(mode):
                return (
                    gr.update(visible=(mode == "Resim YÃ¼kle")),
                    gr.update(visible=(mode == "Metin Gir"))
                )

            input_mode.change(
                fn=toggle_input_visibility,
                inputs=input_mode,
                outputs=[input_img, input_text]
            )

            # Ana fonksiyon sarmalayÄ±cÄ±
            def wrapper_fn(mode, img_path, text_input, background_path, query):
                try:
                    if mode == "Resim YÃ¼kle":
                        if not os.path.exists(background_path):
                            raise gr.Error("Arka plan dosyasÄ± bulunamadÄ±!")
                        if not os.path.exists(img_path):
                            raise gr.Error("Nesne gÃ¶rseli bulunamadÄ±!")
                        
                        background_image = Image.open(background_path).convert("RGB")
                        return all_function(img_path, query, background_image)
                    else:
                        # Metin giriÅŸi (URL) durumu
                        if not text_input.startswith(("http://", "https://")):
                            raise gr.Error("GeÃ§erli bir URL giriniz!")
                            
                        # URL'den gÃ¶rseli indir ve iÅŸle
                        response = requests.get(text_input, timeout=10)
                        if response.status_code != 200:
                            raise gr.Error("URL'den gÃ¶rsel indirilemedi!")
                            
                        image = Image.open(BytesIO(response.content)).convert("RGB")
                        
                        if not os.path.exists(background_path):
                            raise gr.Error("Arka plan dosyasÄ± bulunamadÄ±!")
                            
                        background_image = Image.open(background_path).convert("RGB")
                        return all_function(image, query, background_image)
                        
                except Exception as e:
                    raise gr.Error(f"Ä°ÅŸlem sÄ±rasÄ±nda hata oluÅŸtu: {str(e)}")

            submit_button.click(
                fn=wrapper_fn,
                inputs=[input_mode, input_img, input_text, background_img, query_text],
                outputs=output_image
            )



        with gr.TabItem("GÃ¶rÃ¼ntÃ¼-Metin BenzerliÄŸi (CLIP)"):
            gr.Markdown("**CLIP modeli ile gÃ¶rÃ¼ntÃ¼ ve metin arasÄ±ndaki benzerlik analizi**")
            gr.Markdown("AÅŸaÄŸÄ±ya bir resim yÃ¼kleyin ve virgÃ¼lle ayÄ±rarak karÅŸÄ±laÅŸtÄ±rmak istediÄŸiniz metinleri girin. Ã–rneÄŸin: `kedi, kÃ¶pek, araba, deniz`")
            
            with gr.Row():
                image_input = gr.Image(type="pil", label="GÃ¶rÃ¼ntÃ¼ YÃ¼kle")
                text_input = gr.Textbox(label="Metinleri girin (virgÃ¼lle ayÄ±rÄ±n)", placeholder="Ã¶rneÄŸin: kedi, kÃ¶pek, deniz")
            
            output = gr.Label(label="Benzerlik SonuÃ§larÄ± (YÃ¼ksekten dÃ¼ÅŸÃ¼ÄŸe)")
            button = gr.Button("BenzerliÄŸi Hesapla")

            button.click(fn=clip_similarity_1, inputs=[image_input, text_input], outputs=output)
            
        with gr.TabItem("GÃ¶rsel Soru-Cevap (Gemini)"): 
            gr.Markdown("**Gemini ile gÃ¶rsel tabanlÄ± sohbet sistemi.**")
            gr.Markdown("AÅŸaÄŸÄ±ya bir resim yÃ¼kleyin, sonra bu resimle ilgili bir soru sorun. Sohbet ÅŸeklinde devam edebilirsiniz.")

            chatbot = gr.Chatbot(label="GÃ¶rsel Soru-Cevap Chatbot")
            image_input = gr.Image(type="pil", label="GÃ¶rsel YÃ¼kle")
            question_input = gr.Textbox(label="Sorunuzu yazÄ±n ve Enter'a basÄ±n", placeholder="Resimde ne gÃ¶rÃ¼yorsun?")
            state = gr.State([])

            question_input.submit(
                fn=visual_question_answering_chatbot,
                inputs=[state, image_input, question_input],
                outputs=[chatbot, question_input]
            )
            
        with gr.TabItem("GÃ¶rÃ¼ntÃ¼ AÃ§Ä±klama(BLIP)"): 
            gr.Markdown("**Image Captioning - GÃ¶rÃ¼ntÃ¼den metinsel aÃ§Ä±klama Ã¼retme**")
            gr.Markdown("Bir resim yÃ¼kleyin, model otomatik olarak aÃ§Ä±klama Ã¼retsin.")

            image_input = gr.Image(type="pil", label="GÃ¶rsel YÃ¼kle")
            caption_output = gr.Textbox(label="GÃ¶rÃ¼ntÃ¼ AÃ§Ä±klamasÄ±", interactive=False)

            generate_button = gr.Button("AÃ§Ä±klama OluÅŸtur")

            generate_button.click(
                fn=image_description,
                inputs=image_input,
                outputs=caption_output
            )
            
        with gr.TabItem("OCR Metin TanÄ±ma(EasyOCR)"): 
            gr.Markdown("**Optical Character Recognition - GÃ¶rÃ¼ntÃ¼deki metinleri okuma**")
            gr.Markdown("Bir resim yÃ¼kleyin, model iÃ§indeki metni tanÄ±sÄ±n ve Ã§Ä±karsÄ±n.")

            image_input = gr.Image(type="pil", label="GÃ¶rsel YÃ¼kle")
            ocr_output = gr.Textbox(label="Tespit Edilen Metinler", lines=5, interactive=False)

            recognize_button = gr.Button("Metni TanÄ±")

            recognize_button.click(
                fn=extract_text_from_image,
                inputs=image_input,
                outputs=ocr_output
            )
            
        with gr.TabItem("Video Analizi"):
            gr.Markdown("**Video dosyalarÄ±ndan frame Ã§Ä±karma ve analiz etme**")
            gr.Markdown("Bir video yÃ¼kleyin. Sistem her 3 saniyede bir frame Ã§Ä±karÄ±r, ardÄ±ndan CLIP ile en kaliteli 5 gÃ¶rseli seÃ§er.")

            video_input = gr.Video(label="ğŸ¥ Video YÃ¼kle", height=300, width=400)

            top_5_images = gr.Gallery(label="ğŸ” En Ä°yi 5 Frame", columns=5, height="auto", object_fit="contain")

            scores_textbox = gr.Textbox(label="ğŸ¯ Frame SkorlarÄ±", lines=5, interactive=False)

            analyze_button = gr.Button("Analiz Et")

            analyze_button.click(
                fn=analyze_video,
                inputs=video_input,
                outputs=[top_5_images, scores_textbox]
            )
                    
        with gr.TabItem("Ses-Metin DÃ¶nÃ¼ÅŸÃ¼mÃ¼ (Whisper)"):
            gr.Markdown("**Whisper modeli ile konuÅŸmayÄ± metne Ã§evirme**")
            
            audio_input = gr.Audio(label="ğŸ§ Ses DosyasÄ± YÃ¼kle", type="filepath")
            
            lang_dropdown = gr.Dropdown(
                label="Dil SeÃ§in",
                choices=["en", "tr", "de", "fr", "es", "it", "ru"],
                value="en"
            )

            transcribe_button = gr.Button("DÃ¶nÃ¼ÅŸtÃ¼r")

            transcription_output = gr.Textbox(label="ğŸ“ Ã‡Ä±ktÄ± Metin", lines=6)

            transcribe_button.click(
                fn=transcribe_audio,
                inputs=[audio_input, lang_dropdown],
                outputs=transcription_output
            )
            
        with gr.TabItem("MÃ¼zik Analizi"):
            gr.Markdown("**ğŸµ MÃ¼zik dosyalarÄ±nÄ± analiz et ve tÃ¼rÃ¼nÃ¼ tahmin et**")

            music_file = gr.Audio(label="ğŸ¼ MÃ¼zik DosyasÄ±nÄ± YÃ¼kle (.mp3 veya .wav)", type="filepath")
            analyze_button = gr.Button("ğŸ” TÃ¼rÃ¼ Tahmin Et")
            
            status = gr.Markdown("")  

            def genre_wrapper(file_path):
                status_message = "â³ Tahmin yapÄ±lÄ±yor, lÃ¼tfen bekleyin..."
                yield status_message  

                result = classify_music_genre(file_path)
                yield result  

            analyze_button.click(
                fn=genre_wrapper,
                inputs=music_file,
                outputs=status
            )
            
        with gr.TabItem("GÃ¶rsel OluÅŸturma (Stable Diffusion)"):
            gr.Markdown("**ğŸ–¼ï¸ Stable Diffusion ile metinden gÃ¶rsel oluÅŸturma**")

            prompt_input = gr.Textbox(label="ğŸ¯ Prompt (Metin Girdisi)", placeholder="Ã–rn: A futuristic city under the sea")
            generate_button = gr.Button("ğŸ¨ GÃ¶rseli OluÅŸtur")

            status = gr.Markdown("")
            output_image = gr.Image(label="ğŸ–¼ï¸ OluÅŸturulan GÃ¶rsel")

            def stable_diffusion_wrapper(prompt):
                yield "â³ GÃ¶rsel oluÅŸturuluyor, lÃ¼tfen bekleyin...", None
                try:
                    image = stable_diffusion(prompt)
                    yield "âœ… GÃ¶rsel baÅŸarÄ±yla oluÅŸturuldu.", image
                except Exception as e:
                    yield f"âŒ Hata oluÅŸtu: {e}", None

            generate_button.click(
                fn=stable_diffusion_wrapper,
                inputs=prompt_input,
                outputs=[status, output_image]
            )
            
        with gr.TabItem("Style Transfer"):
            gr.Markdown("**GÃ¶rÃ¼ntÃ¼lere style transfer teknikleri uygulama**")

            with gr.Row():
                content_img_input = gr.Image(label="ğŸ–¼ï¸ Ä°Ã§erik GÃ¶rÃ¼ntÃ¼sÃ¼ (Content Image)", type="filepath")
                style_img_input = gr.Image(label="ğŸ¨ Stil GÃ¶rÃ¼ntÃ¼sÃ¼ (Style Image)", type="filepath")

            output_image = gr.Image(label="âœ¨ Stil AktarÄ±lmÄ±ÅŸ GÃ¶rÃ¼ntÃ¼")

            apply_button = gr.Button("ğŸ¯ Stil Transferini Uygula")

            apply_button.click(
                fn=apply_style_transfer,
                inputs=[content_img_input, style_img_input],
                outputs=output_image
            )


demo.launch()